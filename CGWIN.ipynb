{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper Information :\n",
    "    * Generative Well-intentioned Networks \n",
    "    * https://papers.nips.cc/paper/9467-generative-well-intentioned-networks.pdf\n",
    "\n",
    "Authors of code:\n",
    "    * Yasin Berk GÃ¼ltekin - 1942119 - \"e194211@metu.edu.tr\"\n",
    "    * Hasan Ali Duran - 1942119 - \"e194199@metu.edu.tr\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges Encountered When Implementing Paper:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There was not enough detail about how BNN was implemented. The number of layers was not specified. \n",
    "We could not fully obtain the BNN results mentioned in Paper. The BNN we have implemented makes predictions with higher scores. \n",
    "This situation caused difficulties in the exact occurrence of qualitative results.\n",
    "\n",
    "* The biggest problem we encountered during GAN implementation was that it was not clear enough how the\n",
    "Generator and Discriminator inputs should be processed in the model. It was not specified how many layers \n",
    "or what types of layers were used. In addition, the pictures produced by the generator appeared similar to those given\n",
    "as input to the Generator. There was no explanation for how this problem was solved in paper implementation. The new method which is transformation loss used during the Discriminator's loss calculation was not sufficiently explained.(You can find our assumptions for the models(like number of layers and type of layers) in the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-user install because site-packages writeable\n",
      "Created temporary directory: C:\\Users\\Lenovo\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-0hydjnja\n",
      "Created temporary directory: C:\\Users\\Lenovo\\AppData\\Local\\Temp\\pip-req-tracker-42gqps1_\n",
      "Initialized build tracking at C:\\Users\\Lenovo\\AppData\\Local\\Temp\\pip-req-tracker-42gqps1_\n",
      "Created build tracker: C:\\Users\\Lenovo\\AppData\\Local\\Temp\\pip-req-tracker-42gqps1_\n",
      "Entered build tracker: C:\\Users\\Lenovo\\AppData\\Local\\Temp\\pip-req-tracker-42gqps1_\n",
      "Created temporary directory: C:\\Users\\Lenovo\\AppData\\Local\\Temp\\pip-install-2brb3uyx\n",
      "Requirement already satisfied: pyro-ppl in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: tqdm>=4.36 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyro-ppl) (4.42.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyro-ppl) (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyro-ppl) (1.18.1)\n",
      "Requirement already satisfied: pyro-api>=0.1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyro-ppl) (0.1.2)\n",
      "Requirement already satisfied: torch>=1.4.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyro-ppl) (1.5.0)\n",
      "Requirement already satisfied: future in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch>=1.4.0->pyro-ppl) (0.18.2)\n",
      "Cleaning up...\n",
      "Removed build tracker: 'C:\\\\Users\\\\Lenovo\\\\AppData\\\\Local\\\\Temp\\\\pip-req-tracker-42gqps1_'\n"
     ]
    }
   ],
   "source": [
    "!pip install -v pyro-ppl\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import os.path\n",
    "import os\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import subprocess\n",
    "import pyro.distributions as dist\n",
    "import pyro\n",
    "from matplotlib import colors\n",
    "from pyro import optim\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "import Datasets\n",
    "import Utils\n",
    "from Parameters import hyper_parameters as parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameters \n",
    "\n",
    "    \"threshold\": [0.7, 0.8, 0.9],\n",
    "    \"critic_threshold\": 0.95,\n",
    "    \"n_critic\": 5,\n",
    "    \"n_epochs_Classifier\": 30,\n",
    "    \"n_epochs_GAN\": 200000,\n",
    "    \"batch_size\": 128,\n",
    "    \"lr_Classifier\": 0.001,\n",
    "    \"lr_GAN\": 0.0001,\n",
    "    \"b1\": 0.5,\n",
    "    \"b2\": 0.9,\n",
    "    \"latent_dim\": 100,\n",
    "    \"n_classes\": 10,\n",
    "    \"img_size\": 28,\n",
    "    \"channels\": 1,\n",
    "    \"lambda_gp\": 10,\n",
    "    \"lambda_loss\": 10,\n",
    "    \"continue_on_existing_training\": 0,\n",
    "    \"run_download_sh\": 0\n",
    "    \n",
    "    These hyperparameters are set in the Parameters.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "Utils.set_device(cuda)\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
    "\n",
    "img_shape = (parameters[\"channels\"], parameters[\"img_size\"], parameters[\"img_size\"])\n",
    "\n",
    "# ---------------------\n",
    "#  Running Download Script\n",
    "# ---------------------\n",
    "if parameters[\"run_download_sh\"]:\n",
    "    subprocess.call(\"download.sh\", shell=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "#  BNN - Classifier Model\n",
    "# ---------------------\n",
    "class BNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BNN, self).__init__()\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(parameters[\"img_size\"] ** 2, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(1)\n",
    "        return self.out(x)\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "#  Generator Class\n",
    "# ---------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.fc = nn.Linear(parameters[\"latent_dim\"], parameters[\"channels\"] * parameters[\"img_size\"] ** 2)\n",
    "\n",
    "        self.l1 = nn.Sequential(nn.Conv2d(parameters[\"channels\"] * 2, 64, 3, 1, 1), nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv_blocks_for_image = nn.Sequential(\n",
    "            nn.Conv2d(1, 1, 3, stride=2, padding=1),\n",
    "            nn.Dropout2d(0.1),\n",
    "            nn.BatchNorm2d(1, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.Conv2d(128, 256, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.Conv2d(256, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(32, 16, 3, 1, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.BatchNorm2d(16, 0.8),\n",
    "            nn.Conv2d(16, 1, 3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Linear(4 * parameters[\"img_size\"] ** 2, parameters[\"channels\"] * parameters[\"img_size\"] ** 2),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z, img):\n",
    "        # img = play_with_image(img)\n",
    "        first_z = self.fc(z).view(\n",
    "            [parameters[\"batch_size\"], 1, int(parameters[\"img_size\"]), int(parameters[\"img_size\"])])\n",
    "        gen_input = torch.cat((img, first_z), 1)\n",
    "        out = self.l1(gen_input)\n",
    "        generated_img = self.conv_blocks(out)\n",
    "        return generated_img\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "#  Discriminator Class\n",
    "# ---------------------\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)) + parameters[\"n_classes\"], 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        gen_input = torch.cat(\n",
    "            (img.view(parameters[\"img_size\"] * parameters[\"img_size\"], parameters[\"batch_size\"]),\n",
    "             labels.view(parameters[\"n_classes\"], parameters[\"batch_size\"])), 0). \\\n",
    "            view(parameters[\"batch_size\"], parameters[\"img_size\"] * parameters[\"img_size\"] + parameters[\"n_classes\"])\n",
    "        validity = self.model(gen_input)\n",
    "        return validity\n",
    "    \n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "\n",
    "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=parameters[\"lr_GAN\"],\n",
    "                                       betas=(parameters[\"b1\"], parameters[\"b2\"]))\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=parameters[\"lr_GAN\"],\n",
    "                                           betas=(parameters[\"b1\"], parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Model (Bayesian Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BNN()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "#  Stochastic Variational Inference's Module\n",
    "# ---------------------\n",
    "def module(x, y):\n",
    "    priors = {}\n",
    "    for iterator in model.named_parameters():\n",
    "        name, param = iterator\n",
    "        zeros = torch.zeros_like(param.data)\n",
    "        ones = torch.ones_like(param.data)\n",
    "        priors[name] = dist.Normal(loc=zeros,\n",
    "                                   scale=ones)\n",
    "\n",
    "    lifted_module = pyro.random_module(\"module\", model, priors)\n",
    "    lifted_module_method = lifted_module()\n",
    "    lhat = F.log_softmax(lifted_module_method(x), 1)\n",
    "    pyro.sample(\"obs\", dist.Categorical(logits=lhat), obs=y)\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "#  Stochastic Variational Inference's Guide\n",
    "# ---------------------\n",
    "def guide(x, y):\n",
    "    priors = {}\n",
    "    for iterator in model.named_parameters():\n",
    "        name, param = iterator\n",
    "        priors[name] = dist.Normal(loc=pyro.param(name + '.mu', torch.randn_like(param)),\n",
    "                                   scale=F.softplus(pyro.param(name + '.sigma', torch.randn_like(param))))\n",
    "\n",
    "    lifted_module = pyro.random_module('module', model, priors)\n",
    "    return lifted_module()\n",
    "\n",
    "opt = optim.Adam({'lr': parameters[\"lr_Classifier\"]})\n",
    "svi = SVI(module, guide, opt, loss=Trace_ELBO())\n",
    "\n",
    "# ---------------------\n",
    "#  Classifier's prediction method\n",
    "# ---------------------\n",
    "def predict(x, y):\n",
    "    sampled_models = [guide(None, None) for _ in range(parameters[\"n_classes\"])]\n",
    "    yhats = [model(x.to(device)).data for model in sampled_models]\n",
    "    mean = torch.mean(torch.stack(yhats), 0)\n",
    "    predsProbs, preds = torch.max(F.softmax(mean).to(device), 1)\n",
    "    return predsProbs, preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Masked Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating mask to train model with only critic dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\pyro\\primitives.py:406: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
      "  \"modules from `torch.nn.Module` instances.\", FutureWarning)\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "mask = []\n",
    "\n",
    "# ---------------------\n",
    "#  Creates Mask To Train Discriminator With P_Critic\n",
    "# ---------------------\n",
    "def create_critic_mask():\n",
    "    print(\"Creating mask to train model with only critic dataset...\")\n",
    "    for i in range(int(len(Datasets.trainset) / parameters[\"batch_size\"])):\n",
    "        # obtain one batch of training images\n",
    "        dataiter = iter(Datasets.trainloader)\n",
    "        images, labels = dataiter.next()\n",
    "        images, labels = Utils.arrange_data_tensors(images, labels)\n",
    "\n",
    "        predsProbs, preds= predict(images, labels)\n",
    "        # convert output probabilities to predicted class\n",
    "        # predsProbs, preds = torch.max(output, 1)\n",
    "        for j in range(parameters[\"batch_size\"]):\n",
    "            mask.append(1 if predsProbs[j].item() > parameters[\"critic_threshold\"] else 0)\n",
    "\n",
    "\n",
    "create_critic_mask()\n",
    "mask = FloatTensor(mask)\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "#  Sampler Class to use mask\n",
    "# ---------------------\n",
    "class SpecialSampler(torch.utils.data.sampler.Sampler):\n",
    "    def __init__(self, mask, data_source):\n",
    "        self.mask = mask\n",
    "        self.data_source = data_source\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter([i.item() for i in torch.nonzero(mask)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training And Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 11303.319796\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "#  Trains Classifier Model\n",
    "# ---------------------\n",
    "\n",
    "def train_classifier_model():\n",
    "    pyro.clear_param_store()\n",
    "\n",
    "    total_loss = 0\n",
    "    for epoch in range(parameters[\"n_epochs_Classifier\"]):\n",
    "        loss = 0\n",
    "        for x, y in Datasets.trainloader:\n",
    "            loss += svi.step(x.flatten(1).to(device), y.to(device))\n",
    "        total_loss = loss / len(Datasets.trainloader.dataset)\n",
    "        print(\"Epoch: %d Loss: %f\" % (epoch + 1, total_loss))\n",
    "\n",
    "    pyro.get_param_store().save('paramstore.out')\n",
    "    torch.save(model.state_dict(), 'ClassifierModel.pt')\n",
    "\n",
    "# ---------------------\n",
    "#  Trains Generative Adverserial Network model\n",
    "# ---------------------\n",
    "def train_GAN():\n",
    "    sampler = SpecialSampler(mask, Datasets.trainset)\n",
    "    criticLoader = torch.utils.data.DataLoader(\n",
    "        Datasets.trainset,\n",
    "        drop_last=True,\n",
    "        batch_size=parameters[\"batch_size\"],\n",
    "        sampler=sampler,\n",
    "        shuffle=False\n",
    "    )\n",
    "    batches_done = 0\n",
    "    for epoch in range(parameters[\"n_epochs_GAN\"]):\n",
    "        for i, (imgs, labels) in enumerate(criticLoader):\n",
    "            hot_labels = Utils.create_one_hot_label(labels)\n",
    "\n",
    "            real_images = Variable(imgs.type(FloatTensor))\n",
    "            labels = Variable(labels.type(LongTensor))\n",
    "\n",
    "            discriminator_optimizer.zero_grad()\n",
    "\n",
    "            z = Variable(FloatTensor(np.random.normal(0, 1, (parameters[\"batch_size\"], parameters[\"latent_dim\"]))))\n",
    "\n",
    "            generated_images = generator(z, real_images)\n",
    "\n",
    "            d_loss = Utils.calculate_discriminator_loss(discriminator, real_images, generated_images, hot_labels)\n",
    "\n",
    "            d_loss.backward()\n",
    "            discriminator_optimizer.step()\n",
    "\n",
    "            generator_optimizer.zero_grad()\n",
    "\n",
    "            if i % parameters[\"n_critic\"] == 0:\n",
    "                dataiter = iter(Datasets.trainloader)\n",
    "                pr_images, pr_labels = dataiter.next()\n",
    "\n",
    "                pr_images = Variable(pr_images.type(FloatTensor))\n",
    "                pr_labels = Variable(pr_labels.type(LongTensor))\n",
    "\n",
    "                generated_images = generator(z, pr_images)\n",
    "                pr_hot_labels = Utils.create_one_hot_label(pr_labels)\n",
    "\n",
    "                fake_validity = discriminator(generated_images, pr_hot_labels)\n",
    "                # Calculating transformation penalty\n",
    "                transformation_loss = Utils.calculate_transformation_loss(generated_images, svi, pr_labels)\n",
    "\n",
    "                g_loss = -torch.mean(fake_validity) + (parameters[\"lambda_loss\"] * transformation_loss)\n",
    "\n",
    "                g_loss.backward()\n",
    "                generator_optimizer.step()\n",
    "\n",
    "                Utils.print_batch_progress(i, d_loss, g_loss)\n",
    "                if batches_done % 100 == 0:\n",
    "                    save_image(generated_images.data[:25], \"images/wgan/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "\n",
    "                batches_done += batches_done + parameters[\"n_critic\"]\n",
    "\n",
    "        Utils.print_epoch_progress(epoch + 1, d_loss, g_loss)\n",
    "\n",
    "    save_GAN_models()\n",
    "    \n",
    "# ---------------------\n",
    "#  Saves Generator and Discriminator Models\n",
    "# ---------------------\n",
    "def save_GAN_models():\n",
    "    torch.save(generator.state_dict(), 'GeneratorModel.pt')\n",
    "    torch.save(discriminator.state_dict(), 'DiscriminatorModel.pt')\n",
    "   \n",
    "    \n",
    "train_classifier_model()\n",
    "train_GAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.832833\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "#  Test for Classifier\n",
    "# ---------------------\n",
    "def test_classifier():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in Datasets.testloader:\n",
    "        x, y = Utils.arrange_data_tensors(x, y)\n",
    "        predsProbs, preds = predict(x.flatten(1), y)\n",
    "        total += parameters[\"batch_size\"]\n",
    "        correct += (preds == y).sum().item()\n",
    "    print(\"Accuracy: %f\" % (correct / total))\n",
    "\n",
    "test_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "#  Loads Generator and Discriminator Models\n",
    "# ---------------------\n",
    "def load_GAN_models():\n",
    "    generator.load_state_dict(torch.load('GeneratorModel.pt' ,map_location=device))\n",
    "    discriminator.load_state_dict(torch.load('DiscriminatorModel.pt', map_location=device))\n",
    "    \n",
    "# ---------------------\n",
    "#  Trains or loads classifier model\n",
    "# ---------------------\n",
    "def create_classifier_model():\n",
    "    if (not os.path.exists('ClassifierModel.pt') or not os.path.exists('paramstore.out')):\n",
    "        train_classifier_model()\n",
    "        test_classifier()\n",
    "    else:\n",
    "        pyro.get_param_store().load('paramstore.out', map_location=device)\n",
    "        model.load_state_dict(torch.load('ClassifierModel.pt', map_location=device))\n",
    "\n",
    "# ---------------------\n",
    "#  Loads Models Or Trains Classifier, Generator, Discriminator Models\n",
    "# ---------------------\n",
    "def load_or_train_models():\n",
    "    create_classifier_model()\n",
    "\n",
    "    if parameters[\"continue_on_existing_training\"] or (\n",
    "            not (os.path.exists('DiscriminatorModel.pt') or os.path.exists('GeneratorModel.pt'))):\n",
    "        \n",
    "        if parameters[\"continue_on_existing_training\"] == True and (\n",
    "                os.path.exists('DiscriminatorModel.pt') and os.path.exists('GeneratorModel.pt')):\n",
    "            load_GAN_models()\n",
    "\n",
    "        train_GAN()\n",
    "    else:\n",
    "        load_GAN_models()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models And Printing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_models produces quantitive and qualitive results.\n",
    "\n",
    "1)Quantitive result is generating a handwritten number which has a certainty that is under threshold.(Figure 2 from Paper)\n",
    "\n",
    "2)Qualitive result is printing three rows of the \"Table 1\" from the paper.\n",
    "It produces results for [0.7, 0.8, 0.9] thresholds (Three rows of the Table 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images and printing results...\n",
      "-------------------Results for Threshold: 0.700000 -------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Qualitative Results for Threshold----------\n",
      "Original Image : 0.535068 (Prediction Acc) || Old Label:  6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Image: 1.000000 (Prediction Acc) || New Label:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Qualitative Results for Threshold----------\n",
      "\n",
      "----------Quantitative Results for Threshold----------\n",
      "Reject            : 0.063000\n",
      "BNN Accuracy      : 39.682540\n",
      "BNN+GWIN Accuracy : 55.555556\n",
      "Rejected Accuracy : 15\n",
      "Overall Accuracy  : 0.010000\n",
      "Error             : -25.195263\n",
      "----------Quantitative Results for Threshold----------\n",
      "-------------------Results for Threshold: 0.700000 -------------------\n",
      "\n",
      "\n",
      "-------------------Results for Threshold: 0.800000 -------------------\n",
      "----------Qualitative Results for Threshold----------\n",
      "Original Image : 0.593668 (Prediction Acc) || Old Label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Image: 1.000000 (Prediction Acc) || New Label:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Qualitative Results for Threshold----------\n",
      "\n",
      "----------Quantitative Results for Threshold----------\n",
      "Reject            : 0.101000\n",
      "BNN Accuracy      : 42.574257\n",
      "BNN+GWIN Accuracy : 65.346535\n",
      "Rejected Accuracy : 22\n",
      "Overall Accuracy  : 0.023000\n",
      "Error             : -22.546809\n",
      "----------Quantitative Results for Threshold----------\n",
      "-------------------Results for Threshold: 0.800000 -------------------\n",
      "\n",
      "\n",
      "-------------------Results for Threshold: 0.900000 -------------------\n",
      "----------Qualitative Results for Threshold----------\n",
      "Original Image : 0.808852 (Prediction Acc) || Old Label:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Image: 1.000000 (Prediction Acc) || New Label:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Qualitative Results for Threshold----------\n",
      "\n",
      "----------Quantitative Results for Threshold----------\n",
      "Reject            : 0.159000\n",
      "BNN Accuracy      : 35.849057\n",
      "BNN+GWIN Accuracy : 64.779874\n",
      "Rejected Accuracy : 28\n",
      "Overall Accuracy  : 0.046000\n",
      "Error             : -18.195483\n",
      "----------Quantitative Results for Threshold----------\n",
      "-------------------Results for Threshold: 0.900000 -------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "#  Test\n",
    "# ---------------------\n",
    "def test_models():\n",
    "    load_or_train_models()\n",
    "    print(\"Generating images and printing results...\")\n",
    "    for threshold_index in range(len(parameters[\"threshold\"])):\n",
    "        print('-------------------Results for Threshold: %2f -------------------' % parameters[\"threshold\"][threshold_index])\n",
    "        counter = 0\n",
    "        probUnderThreshold = 0\n",
    "        probUnderThresholdButCorrectClassified = 0\n",
    "        probUnderThresholdThenClassifiedCorrectClassified = 0\n",
    "        probAboveThresholdAndCorrectClassified = 0\n",
    "        probAboveThresholdAlsoClassifiedCorrectClassified = 0\n",
    "\n",
    "        for i in range(10):\n",
    "            for j in range(int(len(Datasets.testset) / parameters[\"batch_size\"])):\n",
    "                # obtain one batch of training images\n",
    "                dataiter = iter(Datasets.testloader)\n",
    "                images, labels = dataiter.next()\n",
    "\n",
    "                images, labels = Utils.arrange_data_tensors(images, labels)\n",
    "\n",
    "                predsProbs, preds = predict(images, labels)\n",
    "\n",
    "                for k in range(parameters[\"batch_size\"]):\n",
    "\n",
    "                    idx = (i * int(len(Datasets.testset))) + (j * parameters[\"batch_size\"]) + k\n",
    "\n",
    "                    trueLabel = labels[k].item()\n",
    "                    modelsPrediction = preds[k].item()\n",
    "                    modelsPredictionProb = predsProbs[k].item()\n",
    "\n",
    "                    if (modelsPredictionProb < parameters[\"threshold\"][threshold_index]):\n",
    "                        probUnderThreshold = probUnderThreshold + 1\n",
    "                        if (trueLabel == modelsPrediction):\n",
    "                            probUnderThresholdButCorrectClassified = probUnderThresholdButCorrectClassified + 1\n",
    "                    else:\n",
    "                        if (trueLabel == modelsPrediction):\n",
    "                            probAboveThresholdAndCorrectClassified = probAboveThresholdAndCorrectClassified + 1\n",
    "\n",
    "                    if (predsProbs[k] < parameters[\"threshold\"][threshold_index]):\n",
    "                        #save_image(images[k], \"images/result_images/%d\" % idx + \"_original_image.png\", nrow=1,normalize=True)\n",
    "\n",
    "                        generatedImage = Utils.sample_single_image(images, k, generator,\n",
    "                                                             \"images/result_images/%d\" % idx + \"_generated_image_.png\",\n",
    "                                                             True)\n",
    "                        lastPredsProbs, lastPreds = predict(generatedImage.view(1, 1, 28, 28), labels)\n",
    "\n",
    "                        if not modelsPrediction == trueLabel and lastPreds.item() == trueLabel and counter < 1:\n",
    "                            print('----------Qualitative Results for Threshold----------')\n",
    "                            print('Original Image : %2f (Prediction Acc) || Old Label: %2d' % (predsProbs[k], preds[k]))\n",
    "                            Utils.show_image(images[k])\n",
    "                            print(\"Generated Image: %2f (Prediction Acc) || New Label: %2d\" % (lastPredsProbs.item(), lastPreds.item()))\n",
    "                            Utils.show_image(generatedImage)\n",
    "                            counter = counter + 1\n",
    "                            print('----------Qualitative Results for Threshold----------\\n')\n",
    "\n",
    "                        if (lastPreds.item() == trueLabel):\n",
    "                            probUnderThresholdThenClassifiedCorrectClassified = probUnderThresholdThenClassifiedCorrectClassified + 1\n",
    "\n",
    "        total_images = 100000.0\n",
    "\n",
    "        reject = (float(100 * probUnderThreshold) / total_images)\n",
    "        bnnAcc = (100 * probUnderThresholdButCorrectClassified / probUnderThreshold)\n",
    "        bnn_and_gwinAcc = (100 * probUnderThresholdThenClassifiedCorrectClassified / probUnderThreshold)\n",
    "        overallAcc = (float(100 * (\n",
    "                probUnderThresholdThenClassifiedCorrectClassified - probUnderThresholdButCorrectClassified)) / total_images)\n",
    "        error = (100 * (bnnAcc - bnn_and_gwinAcc)) / probUnderThreshold\n",
    "\n",
    "        print('----------Quantitative Results for Threshold----------')\n",
    "        print('Reject            : %2f' % reject)\n",
    "        print('BNN Accuracy      : %2f' % bnnAcc)\n",
    "        print('BNN+GWIN Accuracy : %2f' % bnn_and_gwinAcc)\n",
    "        print('Rejected Accuracy : %2d' % (bnn_and_gwinAcc - bnnAcc))\n",
    "        print('Overall Accuracy  : %2f' % overallAcc)\n",
    "        print('Error             : %2f' % error)\n",
    "        print('----------Quantitative Results for Threshold----------')\n",
    "\n",
    "        print('-------------------Results for Threshold: %2f -------------------\\n\\n' % parameters[\"threshold\"][threshold_index])\n",
    "\n",
    "        \n",
    "test_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
